{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtCZ0Ib0XM2o",
        "outputId": "0c40b82c-fac3-4899-e39d-1a20f58c0039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled data saved to /content/neg_1000_78.28_SCALED.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "file_path = '/content/neg_1000_78.28.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assuming the sentiment scores are in a column named 'sentiment_score'\n",
        "sentiment_scores = df['Sentiment_Score']\n",
        "\n",
        "# Log scaling (handling negative and zero values by adding a constant)\n",
        "log_scaled = np.log1p(sentiment_scores - sentiment_scores.min() + 1)\n",
        "\n",
        "# Min-Max scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "min_max_scaled = min_max_scaler.fit_transform(sentiment_scores.values.reshape(-1, 1))\n",
        "\n",
        "# Z-score scaling (Standardization)\n",
        "standard_scaler = StandardScaler()\n",
        "z_score_scaled = standard_scaler.fit_transform(sentiment_scores.values.reshape(-1, 1))\n",
        "\n",
        "# Robust scaling (using median and quantiles)\n",
        "robust_scaler = RobustScaler()\n",
        "robust_scaled = robust_scaler.fit_transform(sentiment_scores.values.reshape(-1, 1))\n",
        "\n",
        "# Adding the scaled columns to the DataFrame\n",
        "df['log_scaled'] = log_scaled\n",
        "df['min_max_scaled'] = min_max_scaled\n",
        "df['z_score_scaled'] = z_score_scaled\n",
        "df['robust_scaled'] = robust_scaled\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_file_path = '/content/neg_1000_78.28_SCALED.csv'\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f'Scaled data saved to {output_file_path}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV data\n",
        "file_path = '/TSLA_big_cleaned.csv'  # Replace with your actual file path if different\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Ensure all entries in 'body' are strings and handle missing values\n",
        "data['body'] = data['body'].fillna('').astype(str)\n",
        "\n",
        "\n",
        "# Function to label sentiment based on compound score\n",
        "# def label_sentiment(compound_score):\n",
        "#     return 'Bullish' if compound_score >= 0 else 'Bearish'\n",
        "\n",
        "# Apply sentiment analysis to each row\n",
        "# data['predicted_entities'] = data['body'].apply(lambda x: label_sentiment(sentiment_score(x)))\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (data['entities'] == 'Bearish').sum()\n",
        "# correct_predictions = (data['entities'] == data['predicted_entities']).sum()\n",
        "accuracy = correct_predictions / len(data)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "wuckoqe7XX-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}